{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd42869-d75c-4217-9161-760559c260e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "from tensorflow.python.eager import backprop\n",
    "from tensorflow.python.util import compat\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import tensair_aux as tensair\n",
    "from ResNet50_tensorflow import ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8b1db-3f46-4275-bd6b-6e773487546c",
   "metadata": {},
   "source": [
    "## Define TensorFlow Model\n",
    "\n",
    "One may create a TensorFlow model as usual but extending TensAIR instead of Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a02ad9-4986-4c07-afe0-760b9be5e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESNET50(tensair.TensAIR):\n",
    "    def __init__(self):\n",
    "        super(RESNET50, self).__init__()\n",
    "        self.l1 = ResNet()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aff5c07-d022-4d69-8db7-053828a7a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile TensorFlow model as usual\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "optimizer = 'sgd'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model = RESNET50()\n",
    "model.compile(\n",
    "    loss=loss, \n",
    "    optimizer=optimizer,   \n",
    "    metrics=metrics   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba66737-7710-44a2-9413-4d02b4cfd277",
   "metadata": {},
   "source": [
    "# Prepare model for deployment\n",
    "\n",
    "To prepare the model for deployment, we initialize the TF graph making a test prediction.\n",
    "\n",
    "At last, we initialize the gradients that will be broadcasted via TensAIR (mandatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d498b7b7-57f0-432d-9258-9b8ab0c66f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 16:14:20.714358: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 998ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.zeros((1, 64, 64, 3), dtype=float)\n",
    "\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39efc5a6-8150-4930-862b-d2308c92d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_delta(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c23aad1f-faff-44ed-81f6-4febc7d17406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " res_net (ResNet)            multiple                  23970952  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,888,786\n",
      "Trainable params: 23,917,832\n",
      "Non-trainable params: 23,970,954\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b7ec8-d9c2-40fe-b8f6-ca3252e1d8d5",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "\n",
    "To save the model, we simply define the dimentions and types of the input tensors used during training, a pass those (along with the model) to the tensair.define_signatures function) to obtain the signature of the functions\n",
    "\n",
    "At last, we save the model on the desired location uwing the signatures previously obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7138f3eb-1b4a-4e5d-a61a-0898e21e6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors_dims = [[None,64,64,3],[None]]\n",
    "input_tensors_types = [tf.float32,tf.int32]\n",
    "input_tensors_structure = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95819dff-79ef-400f-b3f6-c079b8a06ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = tensair.define_signatures(model, input_tensors_dims,input_tensors_types,input_tensors_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384a0354-fbbb-4e11-9e13-e0b05a22d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensair_path = os.environ.get(\"TENSAIR_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d9a09-a508-4055-a685-1bb42637dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, re_lu_1_layer_call_fn, re_lu_1_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses while saving (showing 5 of 181). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/mauro.dalleluccatosi/Documents/GitHub-personal/TensAIR/data/resnet50/resnet50_model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/mauro.dalleluccatosi/Documents/GitHub-personal/TensAIR/data/resnet50/resnet50_model.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(tensair_path+\"/data/resnet50/resnet50_model.tf\", save_format=\"tf\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077b78f-ed8b-4283-b01c-5376b3caa513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80272bb2-1efa-4df0-8e68-5c59c6fd7821",
   "metadata": {},
   "source": [
    "# Gradients_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed296cba-24bf-4b3b-8c92-d0fc71bf5cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fdb7696-fb43-44ec-84b7-93879003d8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23917832"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 0\n",
    "\n",
    "for layers in model.delta:    \n",
    "    number_weights = 1\n",
    "    for i in layers.shape:\n",
    "        number_weights  *= i\n",
    "    weights += number_weights\n",
    "    \n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a67dccbb-df65-4ff7-8754-eb1b42aaa785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_size:  95671436\n"
     ]
    }
   ],
   "source": [
    "print('delta_size: ', (weights*4) + 4 + 4 + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2160d4c9-6fa3-46f0-b081-8ba57510bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6a56650-21bf-4867-a555-fa5432480ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_size:  6291992\n"
     ]
    }
   ],
   "source": [
    "print('message_size: ', (((mini_batch_size * 64*64*3) + mini_batch_size) * 4) + 4 + 4 + 8 + 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c362d0-265d-4ee6-9a1f-65822aa219aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
