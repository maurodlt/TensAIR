{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd3829f-75b7-4b8e-b9e9-df9bed70b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "from tensorflow.python.eager import backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e2834-c7cb-4dd3-9436-02ee1ed15dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0569eaa2-41d4-43e7-800a-608600a926ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensAIR(Model):\n",
    "    def __init__(self):\n",
    "        super(TensAIR, self).__init__()\n",
    "        \n",
    "    @tf.function\n",
    "    def single_train_step(self, data):\n",
    "        # Reset metrics (they are averaged in TensAIR)\n",
    "        self.reset_metrics()\n",
    "        \n",
    "        data = data_adapter.expand_1d(data)\n",
    "        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
    "        \n",
    "        with backprop.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(\n",
    "                y, y_pred, sample_weight, regularization_losses=self.losses)\n",
    "        \n",
    "        #calculate accuracy\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "                \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        #Update delta gradients\n",
    "        for i, d in enumerate(self.delta):\n",
    "            if gradients[i] is not None:\n",
    "                d.assign_add(gradients[i])\n",
    "        \n",
    "        #Update delta metrics\n",
    "        self.delta_loss.assign_add(loss)\n",
    "        self.delta_accuracy.assign_add(self.metrics[1].result())\n",
    "\n",
    "        return self.metrics[0].result(),self.metrics[1].result()\n",
    "    \n",
    "    def init_delta(self, trainable_weights):\n",
    "        #Delta from last broadcast\n",
    "        self.delta = [tf.Variable(tf.zeros(tw.shape, dtype=float), trainable=False) for tw in trainable_weights]\n",
    "        self.delta_accuracy = tf.Variable(0, dtype=tf.float32, trainable=False)\n",
    "        self.delta_loss = tf.Variable(0, dtype=tf.float32, trainable=False)\n",
    "        return\n",
    "    \n",
    "    @tf.function\n",
    "    def retrieve_delta(self, empty):\n",
    "        return self.delta_loss,self.delta_accuracy,*self.delta\n",
    "    \n",
    "    @tf.function\n",
    "    def prediction(self, data):\n",
    "        self.reset_metrics()\n",
    "        data = data_adapter.expand_1d(data)\n",
    "        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
    "        \n",
    "        y_pred = self(x, training=False)\n",
    "        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n",
    "        return loss, y_pred\n",
    "    \n",
    "    @tf.function\n",
    "    def apply_gradient(self, *g):\n",
    "        gradients = list(g)\n",
    "        \n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "                 \n",
    "        return {'error' : 0}\n",
    "    \n",
    "    @tf.function\n",
    "    def clear_delta(self, empty):\n",
    "        \n",
    "        for i, d in enumerate(self.delta):\n",
    "            d.assign(tf.zeros(d.shape, dtype=float))\n",
    "        \n",
    "        self.delta_accuracy.assign(0)\n",
    "        self.delta_loss.assign(0)\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def save_variables(self, file):\n",
    "        #file_str = compat.as_text(file.numpy())\n",
    "        #tf.train.Checkpoint(step=self.variables).write(tf.eval(file))\n",
    "        tf.train.Checkpoint(step=self.variables).write(\"trained_variables/variables\")\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def evaluation(self, data):\n",
    "        \n",
    "        self.reset_metrics()\n",
    "        self.reset_states()\n",
    "        \n",
    "        data = data_adapter.expand_1d(data)\n",
    "        x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
    "        \n",
    "        y_pred = self(x, training=False)  \n",
    "        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n",
    "        \n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16a7502-f4e5-47d0-b98d-1e1d5886515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom key function that returns the tensor's name part relevant for sorting\n",
    "def identity_string_key(tensor):\n",
    "    # Simply return the part of the name that includes \"Identity\"\n",
    "    return tensor.name.split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d6125-0272-4470-85c4-0a81c2bb6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_tuple(structure, lst):\n",
    "    if isinstance(structure, tuple):\n",
    "        filled_structure = []\n",
    "        for item in structure:\n",
    "            filled_structure.append(fill_tuple(item, lst))\n",
    "        return tuple(filled_structure)\n",
    "    else:\n",
    "        return lst.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871d650e-90a5-4e20-8906-1de565c4e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_signatures(model, input_tensors_dims, input_tensors_types, input_tensors_structure):\n",
    "    save_variables = model.save_variables.get_concrete_function(tf.TensorSpec([], tf.int32, name='file'))\n",
    "    clear_delta = model.clear_delta.get_concrete_function(tf.TensorSpec([], tf.int32, name='empty'))\n",
    "    retrieve_delta = model.retrieve_delta.get_concrete_function(tf.TensorSpec([], tf.int32, name='empty2'))\n",
    "    \n",
    "    #automatically find shape of input tensors for apply_gradient\n",
    "    retrieve_delta_output = retrieve_delta.outputs #the deltas retrieved are the gradients that will be applied\n",
    "    indexed_items = [(index, item) for index, item in enumerate(retrieve_delta_output[2:])]#create index to store order of the list (and remove loss and acc metrics)\n",
    "    delta_output_sorted = sorted(indexed_items, key=lambda x: identity_string_key(x[1])) #saved_model_cli sort by name alphabetically\n",
    "    delta_output_well_named = [(i[0], tf.TensorSpec(i[1].shape, i[1].dtype, name=f\"apply_gradient_{index:0{5}d}\")) for index, i in enumerate(delta_output_sorted)] #create tensor_shapes in the correct order\n",
    "    delta_output_original_order = [item for index, item in sorted(delta_output_well_named, key=lambda x: x[0])] #return list to original order\n",
    "    apply_gradient = model.apply_gradient.get_concrete_function(*delta_output_original_order)\n",
    "    \n",
    "    evaluate_specs = []\n",
    "    prediction_specs = []\n",
    "    train_specs = []\n",
    "\n",
    "    for index, (dim, t) in enumerate(zip(input_tensors_dims,input_tensors_types)):\n",
    "        evaluate_specs.append(tf.TensorSpec(dim, t, name=f\"evaluate_{index:0{5}d}\"))\n",
    "        prediction_specs.append(tf.TensorSpec(dim, t, name=f\"predict_{index:0{5}d}\"))\n",
    "        train_specs.append(tf.TensorSpec(dim, t, name=f\"train_{index:0{5}d}\"))\n",
    "\n",
    "    evaluate = model.evaluation.get_concrete_function(fill_tuple(input_tensors_structure,evaluate_specs))\n",
    "    prediction = model.prediction.get_concrete_function(fill_tuple(input_tensors_structure,prediction_specs))\n",
    "    train_step = model.single_train_step.get_concrete_function(fill_tuple(input_tensors_structure,train_specs))\n",
    "    \n",
    "    signatures={'apply_gradient': apply_gradient, 'evaluate': evaluate, 'save': save_variables, 'prediction': prediction, 'clear_delta': clear_delta, 'train_step':train_step, 'retrieve_delta':retrieve_delta}\n",
    "    \n",
    "    return signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cbc73d-c5ce-485c-abe7-8ff1941179ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
